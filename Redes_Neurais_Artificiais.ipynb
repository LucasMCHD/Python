{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Redes_Neurais_Artificiais.ipynb","provenance":[],"mount_file_id":"1k5_ArVoEwfIYPcXjHvJExje8YDPYVqMS","authorship_tag":"ABX9TyOvu5yIaGYXRV1hN+F88Hiu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Redes Neurais Artificiais"],"metadata":{"id":"GdBhG280TgBJ"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"CzVnnsogHe-Z","executionInfo":{"status":"ok","timestamp":1657292145168,"user_tz":180,"elapsed":481,"user":{"displayName":"Lucas Machado","userId":"12200887343090683580"}}},"outputs":[],"source":["from sklearn.neural_network import MLPClassifier"]},{"cell_type":"markdown","source":["### Base crédito - 99,80%"],"metadata":{"id":"3iSe84ucT0xc"}},{"cell_type":"code","source":["import pickle\n","with open('/content/drive/MyDrive/Machine Learning/Classificação/credit.pkl', 'rb') as f:\n","  X_credit_treinamento, y_credit_treinamento, X_credit_teste, y_credit_teste = pickle.load(f)"],"metadata":{"id":"xQYnDoUJT4Kp","executionInfo":{"status":"ok","timestamp":1657292187336,"user_tz":180,"elapsed":616,"user":{"displayName":"Lucas Machado","userId":"12200887343090683580"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["rede_neural_credito = MLPClassifier(max_iter= 1500, verbose= True,tol=0.00001, hidden_layer_sizes=(2,2))\n","rede_neural_credito.fit(X_credit_treinamento, y_credit_treinamento)"],"metadata":{"id":"CnsXORVHT_Wr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["previsoes_credit = rede_neural_credito.predict(X_credit_teste)"],"metadata":{"id":"ON36D946azwu","executionInfo":{"status":"ok","timestamp":1657294021077,"user_tz":180,"elapsed":219,"user":{"displayName":"Lucas Machado","userId":"12200887343090683580"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, classification_report\n","accuracy_score(y_credit_teste,previsoes_credit) "],"metadata":{"id":"q0LRXfnxa-hT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from yellowbrick.classifier import ConfusionMatrix\n","cm_credit = ConfusionMatrix(rede_neural_credito)\n","cm_credit.fit(X_credit_treinamento, y_credit_treinamento)\n","cm_credit.score(X_credit_teste, y_credit_teste)"],"metadata":{"id":"VYXF4uzSbK_R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(classification_report(y_credit_teste, previsoes_credit))"],"metadata":{"id":"fa_dFNCCcN1F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###  Base census"],"metadata":{"id":"3I2I0l-_cjB9"}},{"cell_type":"code","source":["import pickle\n","from sklearn.metrics import accuracy_score, classification_report\n","from yellowbrick.classifier import ConfusionMatrix\n","\n","with open('/content/drive/MyDrive/Machine Learning/Classificação/census.pkl', 'rb') as f:\n","  X_census_treinamento, y_census_treinamento, X_census_teste, y_census_teste = pickle.load(f)"],"metadata":{"id":"hAJTG5i0cmo2","executionInfo":{"status":"ok","timestamp":1657294464704,"user_tz":180,"elapsed":935,"user":{"displayName":"Lucas Machado","userId":"12200887343090683580"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["rede_neural_census = MLPClassifier(max_iter= 1000, verbose= True,tol=0.000010,\n","                                   hidden_layer_sizes=(55,55))\n","rede_neural_census.fit(X_census_treinamento, y_census_treinamento)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"462Kt_ofcqrA","executionInfo":{"status":"ok","timestamp":1657295105186,"user_tz":180,"elapsed":114379,"user":{"displayName":"Lucas Machado","userId":"12200887343090683580"}},"outputId":"32a82676-3948-42ce-a027-b047cf5ae7e0"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 1, loss = 0.41587969\n","Iteration 2, loss = 0.32789236\n","Iteration 3, loss = 0.31622152\n","Iteration 4, loss = 0.30758707\n","Iteration 5, loss = 0.30340258\n","Iteration 6, loss = 0.29903233\n","Iteration 7, loss = 0.29571320\n","Iteration 8, loss = 0.29373774\n","Iteration 9, loss = 0.29042723\n","Iteration 10, loss = 0.28798380\n","Iteration 11, loss = 0.28630001\n","Iteration 12, loss = 0.28439835\n","Iteration 13, loss = 0.28183340\n","Iteration 14, loss = 0.28070727\n","Iteration 15, loss = 0.27820917\n","Iteration 16, loss = 0.27701200\n","Iteration 17, loss = 0.27477888\n","Iteration 18, loss = 0.27329243\n","Iteration 19, loss = 0.27211108\n","Iteration 20, loss = 0.27044745\n","Iteration 21, loss = 0.26954872\n","Iteration 22, loss = 0.26677457\n","Iteration 23, loss = 0.26602565\n","Iteration 24, loss = 0.26456270\n","Iteration 25, loss = 0.26149397\n","Iteration 26, loss = 0.26082109\n","Iteration 27, loss = 0.25833839\n","Iteration 28, loss = 0.25766308\n","Iteration 29, loss = 0.25610234\n","Iteration 30, loss = 0.25520285\n","Iteration 31, loss = 0.25272372\n","Iteration 32, loss = 0.25101695\n","Iteration 33, loss = 0.25058292\n","Iteration 34, loss = 0.24834379\n","Iteration 35, loss = 0.24736055\n","Iteration 36, loss = 0.24547514\n","Iteration 37, loss = 0.24407451\n","Iteration 38, loss = 0.24365257\n","Iteration 39, loss = 0.24227548\n","Iteration 40, loss = 0.24090907\n","Iteration 41, loss = 0.23964955\n","Iteration 42, loss = 0.23843892\n","Iteration 43, loss = 0.23766510\n","Iteration 44, loss = 0.23597669\n","Iteration 45, loss = 0.23482238\n","Iteration 46, loss = 0.23374859\n","Iteration 47, loss = 0.23333687\n","Iteration 48, loss = 0.23203367\n","Iteration 49, loss = 0.22983111\n","Iteration 50, loss = 0.22960227\n","Iteration 51, loss = 0.22860721\n","Iteration 52, loss = 0.22829966\n","Iteration 53, loss = 0.22663304\n","Iteration 54, loss = 0.22615623\n","Iteration 55, loss = 0.22490788\n","Iteration 56, loss = 0.22350887\n","Iteration 57, loss = 0.22271688\n","Iteration 58, loss = 0.22238627\n","Iteration 59, loss = 0.22141104\n","Iteration 60, loss = 0.21985175\n","Iteration 61, loss = 0.21993025\n","Iteration 62, loss = 0.21826780\n","Iteration 63, loss = 0.21875421\n","Iteration 64, loss = 0.21727776\n","Iteration 65, loss = 0.21793324\n","Iteration 66, loss = 0.21706489\n","Iteration 67, loss = 0.21530581\n","Iteration 68, loss = 0.21393435\n","Iteration 69, loss = 0.21346984\n","Iteration 70, loss = 0.21360113\n","Iteration 71, loss = 0.21204867\n","Iteration 72, loss = 0.21140441\n","Iteration 73, loss = 0.21034433\n","Iteration 74, loss = 0.20907275\n","Iteration 75, loss = 0.20880372\n","Iteration 76, loss = 0.20840818\n","Iteration 77, loss = 0.20766046\n","Iteration 78, loss = 0.20754297\n","Iteration 79, loss = 0.20645295\n","Iteration 80, loss = 0.20663435\n","Iteration 81, loss = 0.20457422\n","Iteration 82, loss = 0.20466339\n","Iteration 83, loss = 0.20333144\n","Iteration 84, loss = 0.20362732\n","Iteration 85, loss = 0.20313138\n","Iteration 86, loss = 0.20382300\n","Iteration 87, loss = 0.20206091\n","Iteration 88, loss = 0.20123077\n","Iteration 89, loss = 0.20073270\n","Iteration 90, loss = 0.20137468\n","Iteration 91, loss = 0.19902246\n","Iteration 92, loss = 0.19929058\n","Iteration 93, loss = 0.19863141\n","Iteration 94, loss = 0.19928371\n","Iteration 95, loss = 0.19818409\n","Iteration 96, loss = 0.19726839\n","Iteration 97, loss = 0.19699910\n","Iteration 98, loss = 0.19564024\n","Iteration 99, loss = 0.19573399\n","Iteration 100, loss = 0.19517251\n","Iteration 101, loss = 0.19472247\n","Iteration 102, loss = 0.19399057\n","Iteration 103, loss = 0.19304344\n","Iteration 104, loss = 0.19317681\n","Iteration 105, loss = 0.19325248\n","Iteration 106, loss = 0.19161853\n","Iteration 107, loss = 0.19162440\n","Iteration 108, loss = 0.19252827\n","Iteration 109, loss = 0.19141361\n","Iteration 110, loss = 0.18950109\n","Iteration 111, loss = 0.18980798\n","Iteration 112, loss = 0.18879947\n","Iteration 113, loss = 0.18881294\n","Iteration 114, loss = 0.18854227\n","Iteration 115, loss = 0.18806370\n","Iteration 116, loss = 0.18669898\n","Iteration 117, loss = 0.18676866\n","Iteration 118, loss = 0.18797109\n","Iteration 119, loss = 0.18703502\n","Iteration 120, loss = 0.18599141\n","Iteration 121, loss = 0.18543034\n","Iteration 122, loss = 0.18505436\n","Iteration 123, loss = 0.18471522\n","Iteration 124, loss = 0.18482264\n","Iteration 125, loss = 0.18454837\n","Iteration 126, loss = 0.18416704\n","Iteration 127, loss = 0.18381787\n","Iteration 128, loss = 0.18276667\n","Iteration 129, loss = 0.18203770\n","Iteration 130, loss = 0.18355818\n","Iteration 131, loss = 0.18352436\n","Iteration 132, loss = 0.18114461\n","Iteration 133, loss = 0.18044608\n","Iteration 134, loss = 0.18091816\n","Iteration 135, loss = 0.17975370\n","Iteration 136, loss = 0.17939794\n","Iteration 137, loss = 0.17852884\n","Iteration 138, loss = 0.17925097\n","Iteration 139, loss = 0.17861057\n","Iteration 140, loss = 0.17890198\n","Iteration 141, loss = 0.17824822\n","Iteration 142, loss = 0.17802847\n","Iteration 143, loss = 0.17951280\n","Iteration 144, loss = 0.17635677\n","Iteration 145, loss = 0.17635362\n","Iteration 146, loss = 0.17639052\n","Iteration 147, loss = 0.17628219\n","Iteration 148, loss = 0.17624370\n","Iteration 149, loss = 0.17619339\n","Iteration 150, loss = 0.17655661\n","Iteration 151, loss = 0.17542598\n","Iteration 152, loss = 0.17474582\n","Iteration 153, loss = 0.17483508\n","Iteration 154, loss = 0.17390691\n","Iteration 155, loss = 0.17410392\n","Iteration 156, loss = 0.17428440\n","Iteration 157, loss = 0.17320948\n","Iteration 158, loss = 0.17183055\n","Iteration 159, loss = 0.17204498\n","Iteration 160, loss = 0.17158595\n","Iteration 161, loss = 0.17132580\n","Iteration 162, loss = 0.17182961\n","Iteration 163, loss = 0.17191044\n","Iteration 164, loss = 0.17124874\n","Iteration 165, loss = 0.16999963\n","Iteration 166, loss = 0.16998096\n","Iteration 167, loss = 0.17041822\n","Iteration 168, loss = 0.17051019\n","Iteration 169, loss = 0.16974691\n","Iteration 170, loss = 0.16968912\n","Iteration 171, loss = 0.16776472\n","Iteration 172, loss = 0.16824579\n","Iteration 173, loss = 0.16781058\n","Iteration 174, loss = 0.16909890\n","Iteration 175, loss = 0.16805774\n","Iteration 176, loss = 0.16697250\n","Iteration 177, loss = 0.16803198\n","Iteration 178, loss = 0.16603447\n","Iteration 179, loss = 0.16671529\n","Iteration 180, loss = 0.16573566\n","Iteration 181, loss = 0.16606452\n","Iteration 182, loss = 0.16832290\n","Iteration 183, loss = 0.16467345\n","Iteration 184, loss = 0.16510844\n","Iteration 185, loss = 0.16510432\n","Iteration 186, loss = 0.16410400\n","Iteration 187, loss = 0.16526766\n","Iteration 188, loss = 0.16392335\n","Iteration 189, loss = 0.16387661\n","Iteration 190, loss = 0.16273891\n","Iteration 191, loss = 0.16378488\n","Iteration 192, loss = 0.16342399\n","Iteration 193, loss = 0.16256084\n","Iteration 194, loss = 0.16248906\n","Iteration 195, loss = 0.16308846\n","Iteration 196, loss = 0.16286112\n","Iteration 197, loss = 0.16348755\n","Iteration 198, loss = 0.16183329\n","Iteration 199, loss = 0.16177552\n","Iteration 200, loss = 0.16102080\n","Iteration 201, loss = 0.16171253\n","Iteration 202, loss = 0.16136446\n","Iteration 203, loss = 0.16085222\n","Iteration 204, loss = 0.15882820\n","Iteration 205, loss = 0.16067359\n","Iteration 206, loss = 0.16054887\n","Iteration 207, loss = 0.16034337\n","Iteration 208, loss = 0.16093611\n","Iteration 209, loss = 0.15999562\n","Iteration 210, loss = 0.15922905\n","Iteration 211, loss = 0.15805042\n","Iteration 212, loss = 0.15837798\n","Iteration 213, loss = 0.15880687\n","Iteration 214, loss = 0.15712149\n","Iteration 215, loss = 0.15831961\n","Iteration 216, loss = 0.16007284\n","Iteration 217, loss = 0.15816435\n","Iteration 218, loss = 0.15815060\n","Iteration 219, loss = 0.15598364\n","Iteration 220, loss = 0.15802104\n","Iteration 221, loss = 0.15721386\n","Iteration 222, loss = 0.15616529\n","Iteration 223, loss = 0.15725754\n","Iteration 224, loss = 0.15635751\n","Iteration 225, loss = 0.15757599\n","Iteration 226, loss = 0.15487317\n","Iteration 227, loss = 0.15526691\n","Iteration 228, loss = 0.15574909\n","Iteration 229, loss = 0.15571678\n","Iteration 230, loss = 0.15614671\n","Iteration 231, loss = 0.15471462\n","Iteration 232, loss = 0.15458979\n","Iteration 233, loss = 0.15374891\n","Iteration 234, loss = 0.15516424\n","Iteration 235, loss = 0.15636243\n","Iteration 236, loss = 0.15422970\n","Iteration 237, loss = 0.15438239\n","Iteration 238, loss = 0.15483525\n","Iteration 239, loss = 0.15474708\n","Iteration 240, loss = 0.15134435\n","Iteration 241, loss = 0.15214734\n","Iteration 242, loss = 0.15256692\n","Iteration 243, loss = 0.15200281\n","Iteration 244, loss = 0.15093837\n","Iteration 245, loss = 0.15194018\n","Iteration 246, loss = 0.15317128\n","Iteration 247, loss = 0.15251026\n","Iteration 248, loss = 0.15281682\n","Iteration 249, loss = 0.15243362\n","Iteration 250, loss = 0.15203923\n","Iteration 251, loss = 0.15163135\n","Iteration 252, loss = 0.15047789\n","Iteration 253, loss = 0.15015859\n","Iteration 254, loss = 0.15128559\n","Iteration 255, loss = 0.15124753\n","Iteration 256, loss = 0.15002028\n","Iteration 257, loss = 0.15064334\n","Iteration 258, loss = 0.15095933\n","Iteration 259, loss = 0.15020451\n","Iteration 260, loss = 0.15030814\n","Iteration 261, loss = 0.14949923\n","Iteration 262, loss = 0.14998153\n","Iteration 263, loss = 0.15009484\n","Iteration 264, loss = 0.14824701\n","Iteration 265, loss = 0.14930741\n","Iteration 266, loss = 0.14913994\n","Iteration 267, loss = 0.14808908\n","Iteration 268, loss = 0.14720604\n","Iteration 269, loss = 0.14779440\n","Iteration 270, loss = 0.14758204\n","Iteration 271, loss = 0.14843349\n","Iteration 272, loss = 0.14791466\n","Iteration 273, loss = 0.14871741\n","Iteration 274, loss = 0.14678022\n","Iteration 275, loss = 0.14822130\n","Iteration 276, loss = 0.14853515\n","Iteration 277, loss = 0.14685407\n","Iteration 278, loss = 0.14664594\n","Iteration 279, loss = 0.14712199\n","Iteration 280, loss = 0.14707731\n","Iteration 281, loss = 0.14747536\n","Iteration 282, loss = 0.14617773\n","Iteration 283, loss = 0.14862386\n","Iteration 284, loss = 0.14761445\n","Iteration 285, loss = 0.14633271\n","Iteration 286, loss = 0.14651659\n","Iteration 287, loss = 0.14668932\n","Iteration 288, loss = 0.14444134\n","Iteration 289, loss = 0.14610790\n","Iteration 290, loss = 0.14750731\n","Iteration 291, loss = 0.14418414\n","Iteration 292, loss = 0.14492086\n","Iteration 293, loss = 0.14480597\n","Iteration 294, loss = 0.14485816\n","Iteration 295, loss = 0.14490742\n","Iteration 296, loss = 0.14529658\n","Iteration 297, loss = 0.14514112\n","Iteration 298, loss = 0.14420023\n","Iteration 299, loss = 0.14441901\n","Iteration 300, loss = 0.14440180\n","Iteration 301, loss = 0.14578954\n","Iteration 302, loss = 0.14497014\n","Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"]},{"output_type":"execute_result","data":{"text/plain":["MLPClassifier(hidden_layer_sizes=(55, 55), max_iter=1000, tol=1e-05,\n","              verbose=True)"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["previsoes_census = rede_neural_census.predict(X_census_teste)"],"metadata":{"id":"JOAssD4Cd7Tq","executionInfo":{"status":"ok","timestamp":1657295111820,"user_tz":180,"elapsed":253,"user":{"displayName":"Lucas Machado","userId":"12200887343090683580"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["accuracy_score(y_census_teste,previsoes_census) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NTygC-RdeB1g","executionInfo":{"status":"ok","timestamp":1657295112932,"user_tz":180,"elapsed":5,"user":{"displayName":"Lucas Machado","userId":"12200887343090683580"}},"outputId":"d9088bb3-032d-4b47-965b-6295f247111b"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8167860798362334"]},"metadata":{},"execution_count":31}]}]}